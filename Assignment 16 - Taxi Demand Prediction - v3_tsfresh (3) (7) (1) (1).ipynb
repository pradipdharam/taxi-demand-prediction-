{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 16 - Taxi Demand Prediction - Fourier Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Task 1: Incorporate Fourier features as features into Regression models and measure MAPE. <br>\n",
    "\n",
    "* Task 2: Perform hyper-parameter tuning for Regression models.\n",
    "        2a. Linear Regression: Grid Search\n",
    "        2b. Random Forest: Random Search \n",
    "        2c. Xgboost: Random Search\n",
    "* Task 3: Explore more time-series features using Google search/Quora/Stackoverflow to reduce the MAPE to < 12%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Transforms Implementation - thought process and undestanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we have 'ft_5', 'ft_4', 'ft_3', 'ft_2', 'ft_1' which are number of pickups in the previous 5 bins (each bin is 10 minutes interval; 5 bins are 50 minute interval) bins for specific region.\n",
    "* Now, plot x on time axis\n",
    "* Also, number of pickups on y axis; it may number pf pickups in each second OR number of puckups in one minute interval OR number of pickups in 10 minute interval. I can decide any interval, here, we have number of pickups in 10 minute intervals are available\n",
    "* Plot I'll get will be fourier plot from which I have to select top 1 OT top 2 OR top 3 OR top 5, both aplitudes and frequencies as fourier transformed features. So, pass the values (number of pickups) of decided intervals/bins (here we already have values for 5 bins ft_1 to ft_5) within 50 minutes interval to fft function, it will give frequency and amplitude representation, pick top number of f and a (sort f & a, take maximum peaks) as a features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_: \n",
      "    ft_5  ft_4  ft_3  ft_2  ft_1\n",
      "4   137   135   129   150   164\n",
      "Below are 5 complex numbers\n",
      "Y:  [715.         +0.j           3.68033989+39.92412927j\n",
      " -18.68033989 -2.92641453j -18.68033989 +2.92641453j\n",
      "   3.68033989-39.92412927j]\n",
      "Here Y represents amplitude\n",
      "Absolute values 5 complex numbers: \n",
      "[715.          40.09340344  18.90817284  18.90817284  40.09340344]\n",
      "Absolute values first n/2 which is 2 complex numbers: \n",
      "[715.          40.09340344]\n",
      "freq:  [ 0.   0.2  0.4 -0.4 -0.2]\n",
      "Frequencies, first n/2 which is 2 complex numbers: \n",
      "[0.  0.2]\n",
      "\n",
      "Here, looks like np.fft.fftfreq generated positive and negative frequency numbers and we consider only positive frequency numbers and respective amplitudes\n",
      "Here, n/2 is 2 which 2, but we see 3 positive frequencies, its fine to consider 3 freqiencies and amplitudes\n",
      "\n",
      "So, below can be my fourier features, both frequencies and amplitudes\n",
      "frequency1, frequency2, frequency3 :  [0.  0.2 0.4]\n",
      "amplitude1, amplitude2, amplitude3 :  [715.          40.09340344  18.90817284]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "### Fourier Transform undestanding\n",
    "df_train__ = pd.read_csv(\"../input/df_train.csv\")[0:100]\n",
    "print(\"df_train_: \\n\",df_train__.filter(['ft_5','ft_4','ft_3','ft_2','ft_1'])[4:5])\n",
    "\n",
    "n = 5 # We are passing total 5 bins\n",
    "#Each row represent signal\n",
    "signals = np.array(df_train__.filter(['ft_5','ft_4','ft_3','ft_2','ft_1'])[4:5], dtype=float)\n",
    "Y = np.fft.fft(signals)\n",
    "Y = Y.ravel()\n",
    "print(\"Below are 5 complex numbers\")\n",
    "print(\"Y: \", Y)\n",
    "print(\"Here Y represents amplitude\")\n",
    "print(\"Absolute values 5 complex numbers: \")\n",
    "print(np.abs(Y)[:])\n",
    "print(\"Absolute values first n/2 which is 2 complex numbers: \")\n",
    "print(np.abs(Y)[:int(n/2)])\n",
    "\n",
    "## We have 5 bins and each value represents 1 bin; So, n=5, timestep=1\n",
    "#n = 5 # We are passing total 5 bins\n",
    "#print(\"n: \",n)\n",
    "timestep = 1 # one passed value represents one timestep or bin; \n",
    "# it may be the case that we are passing 10 values and 2 values represent 1 bin; \n",
    "# means 10 values represent 5 total bins, that means n is 5 and timestep is 2\n",
    "freq = np.fft.fftfreq(n, d=timestep)\n",
    "print(\"freq: \", freq)\n",
    "print(\"Frequencies, first n/2 which is 2 complex numbers: \")\n",
    "print(freq[:int(n/2)])\n",
    "\n",
    "print(\"\\nHere, looks like np.fft.fftfreq generated positive and negative frequency numbers and we consider only positive frequency numbers and respective amplitudes\")\n",
    "print(\"Here, n/2 is 2 which 2, but we see 3 positive frequencies, its fine to consider 3 freqiencies and amplitudes\")\n",
    "\n",
    "print(\"\\nSo, below can be my fourier features, both frequencies and amplitudes\")\n",
    "print(\"frequency1, frequency2, frequency3 : \", freq[:3])\n",
    "print(\"amplitude1, amplitude2, amplitude3 : \", np.abs(Y)[:3])\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure()\n",
    "#plt.plot( freq[:int(n/2)], np.abs(Y)[:int(n/2)] )\n",
    "plt.plot( freq[:3], np.abs(Y)[:3] )\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Transform Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "#np.set_printoptions(supress=True) \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tsfresh.feature_extraction.settings.EfficientFCParameters as EfficientFCParameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourier_transform(signal, total_bins = 5, num_of_values_representing_one_bin = 1):\n",
    "    n = 5\n",
    "    freq = np.fft.fftfreq(total_bins, d=num_of_values_representing_one_bin)    \n",
    "    #end_freq_index = 3 # Since 3 positive values - HARDCODED; int(n/2)+1 = 3\n",
    "    top_freq = freq[:int(n/2)+1]\n",
    "    \n",
    "    #print(\"signal: \",signal)\n",
    "    #print(\"Processing total \", total_bins , \"bins\")\n",
    "    #print(num_of_values_representing_one_bin, \" value's represent one bin\")\n",
    "    \n",
    "    signal = np.array(signal, dtype=float)\n",
    "    Y = np.fft.fft(signal)\n",
    "    Y = np.abs(Y)\n",
    "    Y = Y.ravel()    \n",
    "     \n",
    "    top_amplitude = Y[:int(n/2)+1]\n",
    "    \n",
    "    #print(\"top_freq: \", top_freq)\n",
    "    #print(\"top_amplitude: \", top_amplitude)\n",
    "    \n",
    "    af = list(np.concatenate((top_freq, top_amplitude), axis=0))\n",
    "        \n",
    "    return af\n",
    "\n",
    "def get_df(fourier_transforms, cols):\n",
    "    df = pd.DataFrame(fourier_transforms)\n",
    "    df.columns=cols    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_: \n",
      "    ft_5  ft_4  ft_3  ft_2  ft_1  ...   weekday  exp_avg   ft  id  time\n",
      "0     0    63   217   189   137  ...         4      150  135   0     0\n",
      "1    63   217   189   137   135  ...         4      139  129   1     1\n",
      "\n",
      "[2 rows x 12 columns]\n",
      "df_test_: \n",
      "    ft_5  ft_4  ft_3  ft_2  ft_1  ...   weekday  exp_avg   ft  id  time\n",
      "0   118   106   104    93   102  ...         4      100  101   0     0\n",
      "1   106   104    93   102   101  ...         4      100  120   1     1\n",
      "\n",
      "[2 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_ = pd.read_csv(\"../input/df_train.csv\")[0:200000]\n",
    "df_test_ = pd.read_csv(\"../input/df_test.csv\")\n",
    "\n",
    "df_train_['id'] = np.arange(0,df_train_.shape[0])\n",
    "df_test_['id']  = np.arange(0,df_test_.shape[0])\n",
    "\n",
    "df_train_['time'] = np.arange(0,df_train_.shape[0])\n",
    "df_test_['time']  = np.arange(0,df_test_.shape[0])\n",
    "\n",
    "print(\"df_train_: \\n\",df_train_.head(2))\n",
    "print(\"df_test_: \\n\",df_test_.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ft_5', 'ft_4', 'ft_3', 'ft_2', 'ft_1', 'lat', 'lon', 'weekday',\n",
       "       'exp_avg', 'ft', 'id', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tsfresh - Generating Time Series Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [04:04<00:00, 21.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 29s, sys: 26.7 s, total: 5min 56s\n",
      "Wall time: 6min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [03:09<00:00, 16.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 19s, sys: 13.1 s, total: 4min 32s\n",
      "Wall time: 5min 5s\n",
      "df_features_train by MinimalFCParameters:  (200000, 56)\n",
      "df_features_test by MinimalFCParameters:  (157200, 56)\n"
     ]
    }
   ],
   "source": [
    "columns_ = list(df_test_.columns)\n",
    "columns_.remove('ft')\n",
    "columns_.remove('time')\n",
    "columns_.remove('ft_5')\n",
    "columns_.remove('ft_4')\n",
    "#columns_.remove('ft_3')\n",
    "#columns_.remove('ft_2')\n",
    "\n",
    "from tsfresh.feature_extraction import EfficientFCParameters, MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "\n",
    "settings = MinimalFCParameters()\n",
    "%time df_features_train = extract_features(df_train_.filter(columns_), column_id=\"id\", default_fc_parameters=settings)\n",
    "%time df_features_test  = extract_features(df_test_.filter(columns_), column_id=\"id\", default_fc_parameters=settings)\n",
    "\n",
    "print(\"df_features_train by MinimalFCParameters: \", df_features_train.shape)\n",
    "print(\"df_features_test by MinimalFCParameters: \", df_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>exp_avg__length</th>\n",
       "      <th>exp_avg__maximum</th>\n",
       "      <th>exp_avg__mean</th>\n",
       "      <th>exp_avg__median</th>\n",
       "      <th>exp_avg__minimum</th>\n",
       "      <th>exp_avg__standard_deviation</th>\n",
       "      <th>exp_avg__sum_values</th>\n",
       "      <th>exp_avg__variance</th>\n",
       "      <th>ft_1__length</th>\n",
       "      <th>ft_1__maximum</th>\n",
       "      <th>ft_1__mean</th>\n",
       "      <th>ft_1__median</th>\n",
       "      <th>ft_1__minimum</th>\n",
       "      <th>ft_1__standard_deviation</th>\n",
       "      <th>ft_1__sum_values</th>\n",
       "      <th>ft_1__variance</th>\n",
       "      <th>ft_2__length</th>\n",
       "      <th>ft_2__maximum</th>\n",
       "      <th>ft_2__mean</th>\n",
       "      <th>ft_2__median</th>\n",
       "      <th>ft_2__minimum</th>\n",
       "      <th>ft_2__standard_deviation</th>\n",
       "      <th>ft_2__sum_values</th>\n",
       "      <th>ft_2__variance</th>\n",
       "      <th>ft_3__length</th>\n",
       "      <th>ft_3__maximum</th>\n",
       "      <th>ft_3__mean</th>\n",
       "      <th>ft_3__median</th>\n",
       "      <th>ft_3__minimum</th>\n",
       "      <th>ft_3__standard_deviation</th>\n",
       "      <th>ft_3__sum_values</th>\n",
       "      <th>ft_3__variance</th>\n",
       "      <th>lat__length</th>\n",
       "      <th>lat__maximum</th>\n",
       "      <th>lat__mean</th>\n",
       "      <th>lat__median</th>\n",
       "      <th>lat__minimum</th>\n",
       "      <th>lat__standard_deviation</th>\n",
       "      <th>lat__sum_values</th>\n",
       "      <th>lat__variance</th>\n",
       "      <th>lon__length</th>\n",
       "      <th>lon__maximum</th>\n",
       "      <th>lon__mean</th>\n",
       "      <th>lon__median</th>\n",
       "      <th>lon__minimum</th>\n",
       "      <th>lon__standard_deviation</th>\n",
       "      <th>lon__sum_values</th>\n",
       "      <th>lon__variance</th>\n",
       "      <th>weekday__length</th>\n",
       "      <th>weekday__maximum</th>\n",
       "      <th>weekday__mean</th>\n",
       "      <th>weekday__median</th>\n",
       "      <th>weekday__minimum</th>\n",
       "      <th>weekday__standard_deviation</th>\n",
       "      <th>weekday__sum_values</th>\n",
       "      <th>weekday__variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  exp_avg__length        ...          weekday__variance\n",
       "id                               ...                           \n",
       "0                     1.0        ...                        0.0\n",
       "1                     1.0        ...                        0.0\n",
       "2                     1.0        ...                        0.0\n",
       "3                     1.0        ...                        0.0\n",
       "4                     1.0        ...                        0.0\n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency1</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>amplitude1</th>\n",
       "      <th>amplitude2</th>\n",
       "      <th>amplitude3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>606.0</td>\n",
       "      <td>272.054425</td>\n",
       "      <td>78.983478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>741.0</td>\n",
       "      <td>142.271167</td>\n",
       "      <td>121.040964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>807.0</td>\n",
       "      <td>111.613759</td>\n",
       "      <td>55.048785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>740.0</td>\n",
       "      <td>64.713604</td>\n",
       "      <td>40.646641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>715.0</td>\n",
       "      <td>40.093403</td>\n",
       "      <td>18.908173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency1  frequency2     ...      amplitude2  amplitude3\n",
       "0         0.0         0.2     ...      272.054425   78.983478\n",
       "1         0.0         0.2     ...      142.271167  121.040964\n",
       "2         0.0         0.2     ...      111.613759   55.048785\n",
       "3         0.0         0.2     ...       64.713604   40.646641\n",
       "4         0.0         0.2     ...       40.093403   18.908173\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourier_transforms_train = list(map(get_fourier_transform, np.array(df_train_.filter(['ft_5','ft_4','ft_3','ft_2','ft_1']))))\n",
    "fourier_transforms_test  = list(map(get_fourier_transform, np.array(df_test_.filter(['ft_5','ft_4','ft_3','ft_2','ft_1']))))\n",
    "cols=['frequency1', 'frequency2', 'frequency3','amplitude1', 'amplitude2', 'amplitude3']\n",
    "df_fourier_transforms_train = get_df(fourier_transforms_train, cols)\n",
    "df_fourier_transforms_test  = get_df(fourier_transforms_test , cols)\n",
    "\n",
    "df_fourier_transforms_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining fourier features with existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ = df_train_.join(pd.DataFrame(\n",
    "    df_fourier_transforms_train, \n",
    "    index=df_train_.index, \n",
    "    columns=['frequency1','frequency2','frequency3','amplitude1','amplitude2','amplitude3']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ = df_test_.join(pd.DataFrame(\n",
    "    df_fourier_transforms_test, \n",
    "    index=df_test_.index, \n",
    "    columns=['frequency1','frequency2','frequency3','amplitude1','amplitude2','amplitude3']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>ft</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>frequency1</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>amplitude1</th>\n",
       "      <th>amplitude2</th>\n",
       "      <th>amplitude3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>606.0</td>\n",
       "      <td>272.054425</td>\n",
       "      <td>78.983478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>741.0</td>\n",
       "      <td>142.271167</td>\n",
       "      <td>121.040964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>807.0</td>\n",
       "      <td>111.613759</td>\n",
       "      <td>55.048785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>150</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>740.0</td>\n",
       "      <td>64.713604</td>\n",
       "      <td>40.646641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>150</td>\n",
       "      <td>164</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>715.0</td>\n",
       "      <td>40.093403</td>\n",
       "      <td>18.908173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ft_5  ft_4  ft_3     ...      amplitude1  amplitude2  amplitude3\n",
       "0     0    63   217     ...           606.0  272.054425   78.983478\n",
       "1    63   217   189     ...           741.0  142.271167  121.040964\n",
       "2   217   189   137     ...           807.0  111.613759   55.048785\n",
       "3   189   137   135     ...           740.0   64.713604   40.646641\n",
       "4   137   135   129     ...           715.0   40.093403   18.908173\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>ft</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>frequency1</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>amplitude1</th>\n",
       "      <th>amplitude2</th>\n",
       "      <th>amplitude3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>106</td>\n",
       "      <td>104</td>\n",
       "      <td>93</td>\n",
       "      <td>102</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>523.0</td>\n",
       "      <td>25.096670</td>\n",
       "      <td>13.347552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>104</td>\n",
       "      <td>93</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>506.0</td>\n",
       "      <td>11.843585</td>\n",
       "      <td>10.330997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>93</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>120</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>520.0</td>\n",
       "      <td>25.705938</td>\n",
       "      <td>17.725821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>120</td>\n",
       "      <td>131</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>547.0</td>\n",
       "      <td>41.129849</td>\n",
       "      <td>27.227478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>120</td>\n",
       "      <td>131</td>\n",
       "      <td>164</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>618.0</td>\n",
       "      <td>69.095799</td>\n",
       "      <td>43.803774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ft_5  ft_4  ft_3     ...      amplitude1  amplitude2  amplitude3\n",
       "0   118   106   104     ...           523.0   25.096670   13.347552\n",
       "1   106   104    93     ...           506.0   11.843585   10.330997\n",
       "2   104    93   102     ...           520.0   25.705938   17.725821\n",
       "3    93   102   101     ...           547.0   41.129849   27.227478\n",
       "4   102   101   120     ...           618.0   69.095799   43.803774\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining time series features with existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>ft</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>frequency1</th>\n",
       "      <th>frequency2</th>\n",
       "      <th>frequency3</th>\n",
       "      <th>amplitude1</th>\n",
       "      <th>amplitude2</th>\n",
       "      <th>amplitude3</th>\n",
       "      <th>exp_avg__length</th>\n",
       "      <th>exp_avg__maximum</th>\n",
       "      <th>exp_avg__mean</th>\n",
       "      <th>exp_avg__median</th>\n",
       "      <th>exp_avg__minimum</th>\n",
       "      <th>exp_avg__standard_deviation</th>\n",
       "      <th>exp_avg__sum_values</th>\n",
       "      <th>exp_avg__variance</th>\n",
       "      <th>ft_1__length</th>\n",
       "      <th>ft_1__maximum</th>\n",
       "      <th>ft_1__mean</th>\n",
       "      <th>ft_1__median</th>\n",
       "      <th>ft_1__minimum</th>\n",
       "      <th>ft_1__standard_deviation</th>\n",
       "      <th>ft_1__sum_values</th>\n",
       "      <th>ft_1__variance</th>\n",
       "      <th>ft_2__length</th>\n",
       "      <th>ft_2__maximum</th>\n",
       "      <th>ft_2__mean</th>\n",
       "      <th>ft_2__median</th>\n",
       "      <th>ft_2__minimum</th>\n",
       "      <th>ft_2__standard_deviation</th>\n",
       "      <th>ft_2__sum_values</th>\n",
       "      <th>ft_2__variance</th>\n",
       "      <th>ft_3__length</th>\n",
       "      <th>ft_3__maximum</th>\n",
       "      <th>ft_3__mean</th>\n",
       "      <th>ft_3__median</th>\n",
       "      <th>ft_3__minimum</th>\n",
       "      <th>ft_3__standard_deviation</th>\n",
       "      <th>ft_3__sum_values</th>\n",
       "      <th>ft_3__variance</th>\n",
       "      <th>lat__length</th>\n",
       "      <th>lat__maximum</th>\n",
       "      <th>lat__mean</th>\n",
       "      <th>lat__median</th>\n",
       "      <th>lat__minimum</th>\n",
       "      <th>lat__standard_deviation</th>\n",
       "      <th>lat__sum_values</th>\n",
       "      <th>lat__variance</th>\n",
       "      <th>lon__length</th>\n",
       "      <th>lon__maximum</th>\n",
       "      <th>lon__mean</th>\n",
       "      <th>lon__median</th>\n",
       "      <th>lon__minimum</th>\n",
       "      <th>lon__standard_deviation</th>\n",
       "      <th>lon__sum_values</th>\n",
       "      <th>lon__variance</th>\n",
       "      <th>weekday__length</th>\n",
       "      <th>weekday__maximum</th>\n",
       "      <th>weekday__mean</th>\n",
       "      <th>weekday__median</th>\n",
       "      <th>weekday__minimum</th>\n",
       "      <th>weekday__standard_deviation</th>\n",
       "      <th>weekday__sum_values</th>\n",
       "      <th>weekday__variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>606.0</td>\n",
       "      <td>272.054425</td>\n",
       "      <td>78.983478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>741.0</td>\n",
       "      <td>142.271167</td>\n",
       "      <td>121.040964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>807.0</td>\n",
       "      <td>111.613759</td>\n",
       "      <td>55.048785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>150</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>740.0</td>\n",
       "      <td>64.713604</td>\n",
       "      <td>40.646641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>150</td>\n",
       "      <td>164</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>715.0</td>\n",
       "      <td>40.093403</td>\n",
       "      <td>18.908173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.776228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.982119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ft_5  ft_4        ...          weekday__sum_values  weekday__variance\n",
       "0     0    63        ...                          4.0                0.0\n",
       "1    63   217        ...                          4.0                0.0\n",
       "2   217   189        ...                          4.0                0.0\n",
       "3   189   137        ...                          4.0                0.0\n",
       "4   137   135        ...                          4.0                0.0\n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ = df_train_.join(pd.DataFrame(\n",
    "    df_features_train, \n",
    "    index=df_train_.index, \n",
    "    columns=list(df_features_train.columns)\n",
    "))\n",
    "\n",
    "df_test_ = df_test_.join(pd.DataFrame(\n",
    "    df_features_test, \n",
    "    index=df_test_.index, \n",
    "    columns=list(df_features_test.columns)\n",
    "))\n",
    "df_train_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining train and test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_:  (200000, 71)\n",
      "y_train_:  (200000,)\n",
      "x_test_:  (157200, 71)\n",
      "y_test_:  (157200,)\n"
     ]
    }
   ],
   "source": [
    "columns_ = list(df_test_.columns)\n",
    "columns_.remove('ft')\n",
    "columns_.remove('id')\n",
    "columns_.remove('time')\n",
    "\n",
    "x_train_ = df_train_.filter(columns_)\n",
    "x_test_  = df_test_.filter(columns_)\n",
    "#x_train = df_features_train\n",
    "#x_test = df_features_test\n",
    "\n",
    "y_train_ = np.ravel(df_train_.filter(['ft']))\n",
    "y_test_ = np.ravel(df_test_.filter(['ft']))\n",
    "\n",
    "print(\"x_train_: \", x_train_.shape)\n",
    "print(\"y_train_: \", y_train_.shape)\n",
    "print(\"x_test_: \", x_test_.shape)\n",
    "print(\"y_test_: \", y_test_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 9s, sys: 1.43 s, total: 13min 10s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "def get_feature_importance_by_rf(x_train, y_train, top_prominent=None):\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    clf = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=0, n_jobs = -1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    df_feature_imp_orders = pd.DataFrame({\n",
    "    \"feature_name\": x_train.columns,\n",
    "    \"importance\": clf.feature_importances_    \n",
    "                                        })\n",
    "    df_feature_imp_orders=df_feature_imp_orders.sort_values('importance',ascending=False)\n",
    "    df_feature_imp_orders = df_feature_imp_orders.iloc[:top_prominent][[\"feature_name\",\"importance\"]]\n",
    "    return df_feature_imp_orders\n",
    "\n",
    "%time feature_importance = get_feature_importance_by_rf(x_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>exp_avg__median</td>\n",
       "      <td>0.199708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exp_avg</td>\n",
       "      <td>0.196029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>exp_avg__minimum</td>\n",
       "      <td>0.159043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>exp_avg__mean</td>\n",
       "      <td>0.152665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>exp_avg__maximum</td>\n",
       "      <td>0.142789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>exp_avg__sum_values</td>\n",
       "      <td>0.109600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>amplitude2</td>\n",
       "      <td>0.004865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>amplitude3</td>\n",
       "      <td>0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ft_5</td>\n",
       "      <td>0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>amplitude1</td>\n",
       "      <td>0.003599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ft_4</td>\n",
       "      <td>0.003564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ft_3__minimum</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ft_3__median</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ft_3__maximum</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ft_3__sum_values</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ft_3</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ft_3__mean</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ft_2__maximum</td>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ft_2__minimum</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ft_2__mean</td>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ft_2__sum_values</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ft_2</td>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ft_2__median</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ft_1__sum_values</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ft_1__maximum</td>\n",
       "      <td>0.000510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ft_1__median</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ft_1__mean</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ft_1__minimum</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ft_1</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lon__mean</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>lat__minimum</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>lat__median</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>lat__maximum</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>lat__sum_values</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>lat__mean</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>lon__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>lon__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>weekday__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>weekday__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>lon__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>lat__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>exp_avg__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>lat__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frequency2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>frequency3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>exp_avg__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ft_1__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ft_1__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ft_1__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ft_2__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>frequency1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lat__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ft_2__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ft_2__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ft_3__length</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ft_3__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>exp_avg__standard_deviation</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ft_3__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>weekday__variance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature_name  importance\n",
       "18              exp_avg__median    0.199708\n",
       "8                       exp_avg    0.196029\n",
       "19             exp_avg__minimum    0.159043\n",
       "17                exp_avg__mean    0.152665\n",
       "16             exp_avg__maximum    0.142789\n",
       "21          exp_avg__sum_values    0.109600\n",
       "13                   amplitude2    0.004865\n",
       "14                   amplitude3    0.004714\n",
       "0                          ft_5    0.003808\n",
       "12                   amplitude1    0.003599\n",
       "1                          ft_4    0.003564\n",
       "43                ft_3__minimum    0.000799\n",
       "42                 ft_3__median    0.000795\n",
       "40                ft_3__maximum    0.000793\n",
       "45             ft_3__sum_values    0.000790\n",
       "2                          ft_3    0.000790\n",
       "41                   ft_3__mean    0.000784\n",
       "32                ft_2__maximum    0.000756\n",
       "35                ft_2__minimum    0.000753\n",
       "33                   ft_2__mean    0.000752\n",
       "37             ft_2__sum_values    0.000742\n",
       "3                          ft_2    0.000735\n",
       "34                 ft_2__median    0.000734\n",
       "29             ft_1__sum_values    0.000511\n",
       "24                ft_1__maximum    0.000510\n",
       "26                 ft_1__median    0.000504\n",
       "25                   ft_1__mean    0.000501\n",
       "27                ft_1__minimum    0.000495\n",
       "4                          ft_1    0.000493\n",
       "57                    lon__mean    0.000434\n",
       "..                          ...         ...\n",
       "51                 lat__minimum    0.000392\n",
       "50                  lat__median    0.000392\n",
       "48                 lat__maximum    0.000389\n",
       "53              lat__sum_values    0.000389\n",
       "49                    lat__mean    0.000387\n",
       "5                           lat    0.000385\n",
       "60      lon__standard_deviation    0.000000\n",
       "62                lon__variance    0.000000\n",
       "63              weekday__length    0.000000\n",
       "68  weekday__standard_deviation    0.000000\n",
       "55                  lon__length    0.000000\n",
       "54                lat__variance    0.000000\n",
       "15              exp_avg__length    0.000000\n",
       "52      lat__standard_deviation    0.000000\n",
       "10                   frequency2    0.000000\n",
       "11                   frequency3    0.000000\n",
       "22            exp_avg__variance    0.000000\n",
       "23                 ft_1__length    0.000000\n",
       "28     ft_1__standard_deviation    0.000000\n",
       "30               ft_1__variance    0.000000\n",
       "31                 ft_2__length    0.000000\n",
       "9                    frequency1    0.000000\n",
       "47                  lat__length    0.000000\n",
       "36     ft_2__standard_deviation    0.000000\n",
       "38               ft_2__variance    0.000000\n",
       "39                 ft_3__length    0.000000\n",
       "44     ft_3__standard_deviation    0.000000\n",
       "20  exp_avg__standard_deviation    0.000000\n",
       "46               ft_3__variance    0.000000\n",
       "70            weekday__variance    0.000000\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining train and test variables based on top imp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top imp features:  ['exp_avg__median', 'exp_avg', 'exp_avg__minimum', 'exp_avg__mean', 'exp_avg__maximum', 'exp_avg__sum_values', 'amplitude2', 'amplitude3', 'ft_5', 'amplitude1', 'ft_4', 'ft_3__minimum', 'ft_3__median', 'ft_3__maximum', 'ft_3__sum_values', 'ft_3', 'ft_3__mean', 'ft_2__maximum', 'ft_2__minimum', 'ft_2__mean', 'ft_2__sum_values', 'ft_2', 'ft_2__median', 'ft_1__sum_values', 'ft_1__maximum', 'ft_1__median', 'ft_1__mean', 'ft_1__minimum', 'ft_1', 'lon__mean', 'lon__median', 'lon__maximum', 'lon', 'weekday__maximum', 'weekday__mean', 'lon__minimum', 'lon__sum_values', 'weekday__median', 'weekday', 'weekday__minimum', 'weekday__sum_values', 'lat__minimum', 'lat__median', 'lat__maximum', 'lat__sum_values', 'lat__mean', 'lat', 'lon__standard_deviation', 'lon__variance', 'weekday__length', 'weekday__standard_deviation', 'lon__length', 'lat__variance', 'exp_avg__length', 'lat__standard_deviation', 'frequency2', 'frequency3', 'exp_avg__variance', 'ft_1__length', 'ft_1__standard_deviation', 'ft_1__variance', 'ft_2__length', 'frequency1', 'lat__length', 'ft_2__standard_deviation', 'ft_2__variance', 'ft_3__length', 'ft_3__standard_deviation', 'exp_avg__standard_deviation', 'ft_3__variance']\n",
      "x_train:  (200000, 70)\n",
      "y_train:  (200000,)\n",
      "x_test:  (157200, 70)\n",
      "y_test:  (157200,)\n"
     ]
    }
   ],
   "source": [
    "columns_ = list(feature_importance.feature_name[0:70])\n",
    "print(\"top imp features: \", columns_)\n",
    "\n",
    "x_train = x_train_.filter(columns_)\n",
    "y_train = np.ravel(df_train_.filter(['ft']))\n",
    "x_test  = x_test_.filter(columns_)\n",
    "y_test = np.ravel(df_test_.filter(['ft']))\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost - hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for number of estimators 100 and fold 1 /5\n",
      "Working for number of estimators 100 and fold 2 /5\n",
      "Working for number of estimators 100 and fold 3 /5\n",
      "Working for number of estimators 100 and fold 4 /5\n",
      "Working for number of estimators 100 and fold 5 /5\n",
      "n_estimator:  100\n",
      "cv_mean_abs_per_errors:  0.1394334426082428 \n",
      "\n",
      "Working for number of estimators 500 and fold 1 /5\n",
      "Working for number of estimators 500 and fold 2 /5\n",
      "Working for number of estimators 500 and fold 3 /5\n",
      "Working for number of estimators 500 and fold 4 /5\n",
      "Working for number of estimators 500 and fold 5 /5\n",
      "n_estimator:  500\n",
      "cv_mean_abs_per_errors:  0.13942232464872964 \n",
      "\n",
      "Working for number of estimators 1000 and fold 1 /5\n",
      "Working for number of estimators 1000 and fold 2 /5\n",
      "Working for number of estimators 1000 and fold 3 /5\n",
      "Working for number of estimators 1000 and fold 4 /5\n",
      "Working for number of estimators 1000 and fold 5 /5\n",
      "n_estimator:  1000\n",
      "cv_mean_abs_per_errors:  0.1400571694106663 \n",
      "\n",
      "Working for number of estimators 1500 and fold 1 /5\n",
      "Working for number of estimators 1500 and fold 2 /5\n",
      "Working for number of estimators 1500 and fold 3 /5\n",
      "Working for number of estimators 1500 and fold 4 /5\n",
      "Working for number of estimators 1500 and fold 5 /5\n",
      "n_estimator:  1500\n",
      "cv_mean_abs_per_errors:  0.14055865528676761 \n",
      "\n",
      "Working for number of estimators 2000 and fold 1 /5\n",
      "Working for number of estimators 2000 and fold 2 /5\n",
      "Working for number of estimators 2000 and fold 3 /5\n",
      "Working for number of estimators 2000 and fold 4 /5\n",
      "Working for number of estimators 2000 and fold 5 /5\n",
      "n_estimator:  2000\n",
      "cv_mean_abs_per_errors:  0.14102352714717417 \n",
      "\n",
      "Working for number of estimators 2500 and fold 1 /5\n",
      "Working for number of estimators 2500 and fold 2 /5\n",
      "Working for number of estimators 2500 and fold 3 /5\n",
      "Working for number of estimators 2500 and fold 4 /5\n",
      "Working for number of estimators 2500 and fold 5 /5\n",
      "n_estimator:  2500\n",
      "cv_mean_abs_per_errors:  0.14153157324248394 \n",
      "\n",
      "Working for number of estimators 3000 and fold 1 /5\n",
      "Working for number of estimators 3000 and fold 2 /5\n",
      "Working for number of estimators 3000 and fold 3 /5\n",
      "Working for number of estimators 3000 and fold 4 /5\n",
      "Working for number of estimators 3000 and fold 5 /5\n",
      "n_estimator:  3000\n",
      "cv_mean_abs_per_errors:  0.14194620111838047 \n",
      "\n",
      "cv_mean_abs_per_errors:  [0.1394334426082428, 0.13942232464872964, 0.1400571694106663, 0.14055865528676761, 0.14102352714717417, 0.14153157324248394, 0.14194620111838047] \n",
      "\n",
      "optimal_n_entimator:  500\n",
      "CV_MAPE:  0.13942232464872964\n",
      "Test_MAPE:  0.1278225593369669\n",
      "CPU times: user 4h 17min 22s, sys: 14 s, total: 4h 17min 36s\n",
      "Wall time: 1h 5min 1s\n"
     ]
    }
   ],
   "source": [
    "def XGBRegressor_Tunning(x_train, y_train, x_test, y_test):\n",
    "    n_estimators = [100, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "    #n_estimators = [2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000]\n",
    "    #n_estimators = np.arange(100,2100,100)\n",
    "    \n",
    "    #cv_mean_square_errors = []\n",
    "    cv_mean_abs_per_errors = []\n",
    "    # perform 10-fold cross validation\n",
    "    time_series_10foldcv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    for n_estimator in n_estimators:\n",
    "        clf = xgb.XGBRegressor(n_estimators = n_estimator, n_jobs = -1)\n",
    "        this_mape=[]\n",
    "        fold_number = 1\n",
    "        for train_index, cv_index in time_series_10foldcv.split(x_train):\n",
    "            print(\"Working for number of estimators\", n_estimator, \"and fold\",fold_number,\"/5\")\n",
    "            #print(\"train_index: \", train_index)\n",
    "            #print(\"cv_index: \", cv_index)\n",
    "            X_train, X_cv = x_train[train_index], x_train[cv_index]            \n",
    "            Y_train, Y_cv = y_train[train_index], y_train[cv_index]   \n",
    "            \n",
    "            clf.fit(X_train, Y_train)\n",
    "            pred = clf.predict(X_cv)\n",
    "            mae = mean_absolute_error(Y_cv, pred)\n",
    "            mape = mae/(sum(Y_cv)/len(Y_cv))\n",
    "            this_mape.append(mape)\n",
    "            fold_number = fold_number + 1\n",
    "        \n",
    "        #cv_mean_square_errors.append(np.average(this_mse))    \n",
    "        cv_mean_abs_per_errors.append(np.average(this_mape))        \n",
    "        print(\"n_estimator: \", n_estimator)\n",
    "        #print(\"cv_mean_square_error \", cv_mean_square_errors[-1])\n",
    "        print(\"cv_mean_abs_per_errors: \", cv_mean_abs_per_errors[-1],\"\\n\")\n",
    "       \n",
    "    #print(\"cv_mean_square_errors: \", cv_mean_square_errors)\n",
    "    print(\"cv_mean_abs_per_errors: \", cv_mean_abs_per_errors,\"\\n\")\n",
    "     \n",
    "    best_estimator_index_mape = cv_mean_abs_per_errors.index(min(cv_mean_abs_per_errors))\n",
    "    optimal_n_entimator = n_estimators[best_estimator_index_mape]\n",
    "    CV_MAPE = cv_mean_abs_per_errors[best_estimator_index_mape]\n",
    "    print(\"optimal_n_entimator: \", optimal_n_entimator)\n",
    "    print(\"CV_MAPE: \", CV_MAPE)    \n",
    "    \n",
    "    clf = xgb.XGBRegressor(n_estimators=optimal_n_entimator, n_jobs = -1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mape = mae/(sum(y_test)/len(y_test))\n",
    "    print(\"Test_MAPE: \", mape)\n",
    "       \n",
    "%time XGBRegressor_Tunning(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost - hyper parameter tunning - with top 47 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top imp features:  ['exp_avg__median', 'exp_avg', 'exp_avg__minimum', 'exp_avg__mean', 'exp_avg__maximum', 'exp_avg__sum_values', 'amplitude2', 'amplitude3', 'ft_5', 'amplitude1', 'ft_4', 'ft_3__minimum', 'ft_3__median', 'ft_3__maximum', 'ft_3__sum_values', 'ft_3', 'ft_3__mean', 'ft_2__maximum', 'ft_2__minimum', 'ft_2__mean', 'ft_2__sum_values', 'ft_2', 'ft_2__median', 'ft_1__sum_values', 'ft_1__maximum', 'ft_1__median', 'ft_1__mean', 'ft_1__minimum', 'ft_1', 'lon__mean', 'lon__median', 'lon__maximum', 'lon', 'weekday__maximum', 'weekday__mean', 'lon__minimum', 'lon__sum_values', 'weekday__median', 'weekday', 'weekday__minimum', 'weekday__sum_values', 'lat__minimum', 'lat__median', 'lat__maximum', 'lat__sum_values', 'lat__mean', 'lat']\n",
      "x_train:  (200000, 47)\n",
      "y_train:  (200000,)\n",
      "x_test:  (157200, 47)\n",
      "y_test:  (157200,)\n",
      "Working for number of estimators 100 and fold 1 /5\n",
      "Working for number of estimators 100 and fold 2 /5\n",
      "Working for number of estimators 100 and fold 3 /5\n",
      "Working for number of estimators 100 and fold 4 /5\n",
      "Working for number of estimators 100 and fold 5 /5\n",
      "n_estimator:  100\n",
      "cv_mean_abs_per_errors:  0.1394334426082428 \n",
      "\n",
      "Working for number of estimators 500 and fold 1 /5\n",
      "Working for number of estimators 500 and fold 2 /5\n",
      "Working for number of estimators 500 and fold 3 /5\n",
      "Working for number of estimators 500 and fold 4 /5\n",
      "Working for number of estimators 500 and fold 5 /5\n",
      "n_estimator:  500\n",
      "cv_mean_abs_per_errors:  0.13942232464872964 \n",
      "\n",
      "Working for number of estimators 1000 and fold 1 /5\n",
      "Working for number of estimators 1000 and fold 2 /5\n",
      "Working for number of estimators 1000 and fold 3 /5\n",
      "Working for number of estimators 1000 and fold 4 /5\n",
      "Working for number of estimators 1000 and fold 5 /5\n",
      "n_estimator:  1000\n",
      "cv_mean_abs_per_errors:  0.1400571694106663 \n",
      "\n",
      "Working for number of estimators 1500 and fold 1 /5\n",
      "Working for number of estimators 1500 and fold 2 /5\n",
      "Working for number of estimators 1500 and fold 3 /5\n",
      "Working for number of estimators 1500 and fold 4 /5\n",
      "Working for number of estimators 1500 and fold 5 /5\n",
      "n_estimator:  1500\n",
      "cv_mean_abs_per_errors:  0.14055865528676761 \n",
      "\n",
      "Working for number of estimators 2000 and fold 1 /5\n",
      "Working for number of estimators 2000 and fold 2 /5\n",
      "Working for number of estimators 2000 and fold 3 /5\n",
      "Working for number of estimators 2000 and fold 4 /5\n",
      "Working for number of estimators 2000 and fold 5 /5\n",
      "n_estimator:  2000\n",
      "cv_mean_abs_per_errors:  0.14102352714717417 \n",
      "\n",
      "Working for number of estimators 2500 and fold 1 /5\n",
      "Working for number of estimators 2500 and fold 2 /5\n",
      "Working for number of estimators 2500 and fold 3 /5\n",
      "Working for number of estimators 2500 and fold 4 /5\n",
      "Working for number of estimators 2500 and fold 5 /5\n",
      "n_estimator:  2500\n",
      "cv_mean_abs_per_errors:  0.14153157324248394 \n",
      "\n",
      "Working for number of estimators 3000 and fold 1 /5\n",
      "Working for number of estimators 3000 and fold 2 /5\n",
      "Working for number of estimators 3000 and fold 3 /5\n",
      "Working for number of estimators 3000 and fold 4 /5\n",
      "Working for number of estimators 3000 and fold 5 /5\n",
      "n_estimator:  3000\n",
      "cv_mean_abs_per_errors:  0.14194620111838047 \n",
      "\n",
      "cv_mean_abs_per_errors:  [0.1394334426082428, 0.13942232464872964, 0.1400571694106663, 0.14055865528676761, 0.14102352714717417, 0.14153157324248394, 0.14194620111838047] \n",
      "\n",
      "optimal_n_entimator:  500\n",
      "CV_MAPE:  0.13942232464872964\n",
      "Test_MAPE:  0.1278225593369669\n",
      "CPU times: user 3h 14min 1s, sys: 10.4 s, total: 3h 14min 12s\n",
      "Wall time: 48min 59s\n"
     ]
    }
   ],
   "source": [
    "columns_ = list(feature_importance.feature_name[0:47])\n",
    "print(\"top imp features: \", columns_)\n",
    "\n",
    "x_train = x_train_.filter(columns_)\n",
    "y_train = np.ravel(df_train_.filter(['ft']))\n",
    "x_test  = x_test_.filter(columns_)\n",
    "y_test = np.ravel(df_test_.filter(['ft']))\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "%time XGBRegressor_Tunning(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost - hyper parameter tunning - with top 11 features with lat, log and and weekday features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* feature_name\timportance\n",
    "* 18\texp_avg__median\t0.199708\n",
    "* 8\texp_avg\t0.196029\n",
    "* 19\texp_avg__minimum\t0.159043\n",
    "* 17\texp_avg__mean\t0.152665\n",
    "* 16\texp_avg__maximum\t0.142789\n",
    "* 21\texp_avg__sum_values\t0.109600\n",
    "* 13\tamplitude2\t0.004865\n",
    "* 14\tamplitude3\t0.004714**\n",
    "* 0\tft_5\t0.003808\n",
    "* 12\tamplitude1\t0.003599\n",
    "* 1\tft_4\t0.003564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (200000, 14)\n",
      "y_train:  (200000,)\n",
      "x_test:  (157200, 14)\n",
      "y_test:  (157200,)\n",
      "Working for number of estimators 100 and fold 1 /5\n",
      "Working for number of estimators 100 and fold 2 /5\n",
      "Working for number of estimators 100 and fold 3 /5\n",
      "Working for number of estimators 100 and fold 4 /5\n",
      "Working for number of estimators 100 and fold 5 /5\n",
      "n_estimator:  100\n",
      "cv_mean_abs_per_errors:  0.13926305785438592 \n",
      "\n",
      "Working for number of estimators 500 and fold 1 /5\n",
      "Working for number of estimators 500 and fold 2 /5\n",
      "Working for number of estimators 500 and fold 3 /5\n",
      "Working for number of estimators 500 and fold 4 /5\n",
      "Working for number of estimators 500 and fold 5 /5\n",
      "n_estimator:  500\n",
      "cv_mean_abs_per_errors:  0.1403056785085324 \n",
      "\n",
      "Working for number of estimators 1000 and fold 1 /5\n",
      "Working for number of estimators 1000 and fold 2 /5\n",
      "Working for number of estimators 1000 and fold 3 /5\n",
      "Working for number of estimators 1000 and fold 4 /5\n",
      "Working for number of estimators 1000 and fold 5 /5\n",
      "n_estimator:  1000\n",
      "cv_mean_abs_per_errors:  0.14118426101780507 \n",
      "\n",
      "Working for number of estimators 1500 and fold 1 /5\n",
      "Working for number of estimators 1500 and fold 2 /5\n",
      "Working for number of estimators 1500 and fold 3 /5\n",
      "Working for number of estimators 1500 and fold 4 /5\n",
      "Working for number of estimators 1500 and fold 5 /5\n",
      "n_estimator:  1500\n",
      "cv_mean_abs_per_errors:  0.14194303518850448 \n",
      "\n",
      "Working for number of estimators 2000 and fold 1 /5\n",
      "Working for number of estimators 2000 and fold 2 /5\n",
      "Working for number of estimators 2000 and fold 3 /5\n",
      "Working for number of estimators 2000 and fold 4 /5\n",
      "Working for number of estimators 2000 and fold 5 /5\n",
      "n_estimator:  2000\n",
      "cv_mean_abs_per_errors:  0.1424623059388787 \n",
      "\n",
      "Working for number of estimators 2500 and fold 1 /5\n",
      "Working for number of estimators 2500 and fold 2 /5\n",
      "Working for number of estimators 2500 and fold 3 /5\n",
      "Working for number of estimators 2500 and fold 4 /5\n",
      "Working for number of estimators 2500 and fold 5 /5\n",
      "n_estimator:  2500\n",
      "cv_mean_abs_per_errors:  0.1430145467094004 \n",
      "\n",
      "Working for number of estimators 3000 and fold 1 /5\n",
      "Working for number of estimators 3000 and fold 2 /5\n",
      "Working for number of estimators 3000 and fold 3 /5\n",
      "Working for number of estimators 3000 and fold 4 /5\n",
      "Working for number of estimators 3000 and fold 5 /5\n",
      "n_estimator:  3000\n",
      "cv_mean_abs_per_errors:  0.14344246063112623 \n",
      "\n",
      "cv_mean_abs_per_errors:  [0.13926305785438592, 0.1403056785085324, 0.14118426101780507, 0.14194303518850448, 0.1424623059388787, 0.1430145467094004, 0.14344246063112623] \n",
      "\n",
      "optimal_n_entimator:  100\n",
      "CV_MAPE:  0.13926305785438592\n",
      "Test_MAPE:  0.1285207907019917\n",
      "CPU times: user 1h 39min 5s, sys: 5.12 s, total: 1h 39min 10s\n",
      "Wall time: 24min 59s\n"
     ]
    }
   ],
   "source": [
    "#columns_ = list(feature_importance.feature_name[0:47])\n",
    "#print(\"top imp features: \", columns_)\n",
    "columns_ = ['lat', 'lon', 'weekday','exp_avg__median', 'exp_avg', 'exp_avg__minimum','exp_avg__mean','exp_avg__maximum','exp_avg__sum_values','amplitude2','amplitude3','ft_5','amplitude1','ft_4']\n",
    "\n",
    "x_train = x_train_.filter(columns_)\n",
    "y_train = np.ravel(df_train_.filter(['ft']))\n",
    "x_test  = x_test_.filter(columns_)\n",
    "y_test = np.ravel(df_test_.filter(['ft']))\n",
    "\n",
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "%time XGBRegressor_Tunning(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost - hyper parameter tunning - with top 11 features with lat, log and and weekday features - for n_estimators from 10,20,...,100 to check the MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for number of estimators 10 and fold 1 /5\n",
      "Working for number of estimators 10 and fold 2 /5\n",
      "Working for number of estimators 10 and fold 3 /5\n",
      "Working for number of estimators 10 and fold 4 /5\n",
      "Working for number of estimators 10 and fold 5 /5\n",
      "n_estimator:  10\n",
      "cv_mean_abs_per_errors:  0.3633849439423973 \n",
      "\n",
      "Working for number of estimators 20 and fold 1 /5\n",
      "Working for number of estimators 20 and fold 2 /5\n",
      "Working for number of estimators 20 and fold 3 /5\n",
      "Working for number of estimators 20 and fold 4 /5\n",
      "Working for number of estimators 20 and fold 5 /5\n",
      "n_estimator:  20\n",
      "cv_mean_abs_per_errors:  0.17806605709326323 \n",
      "\n",
      "Working for number of estimators 30 and fold 1 /5\n",
      "Working for number of estimators 30 and fold 2 /5\n",
      "Working for number of estimators 30 and fold 3 /5\n",
      "Working for number of estimators 30 and fold 4 /5\n",
      "Working for number of estimators 30 and fold 5 /5\n",
      "n_estimator:  30\n",
      "cv_mean_abs_per_errors:  0.14427056377075045 \n",
      "\n",
      "Working for number of estimators 40 and fold 1 /5\n",
      "Working for number of estimators 40 and fold 2 /5\n",
      "Working for number of estimators 40 and fold 3 /5\n",
      "Working for number of estimators 40 and fold 4 /5\n",
      "Working for number of estimators 40 and fold 5 /5\n",
      "n_estimator:  40\n",
      "cv_mean_abs_per_errors:  0.1398210999522589 \n",
      "\n",
      "Working for number of estimators 50 and fold 1 /5\n",
      "Working for number of estimators 50 and fold 2 /5\n",
      "Working for number of estimators 50 and fold 3 /5\n",
      "Working for number of estimators 50 and fold 4 /5\n",
      "Working for number of estimators 50 and fold 5 /5\n",
      "n_estimator:  50\n",
      "cv_mean_abs_per_errors:  0.1395061954011377 \n",
      "\n",
      "Working for number of estimators 60 and fold 1 /5\n",
      "Working for number of estimators 60 and fold 2 /5\n",
      "Working for number of estimators 60 and fold 3 /5\n",
      "Working for number of estimators 60 and fold 4 /5\n",
      "Working for number of estimators 60 and fold 5 /5\n",
      "n_estimator:  60\n",
      "cv_mean_abs_per_errors:  0.1395559301829652 \n",
      "\n",
      "Working for number of estimators 70 and fold 1 /5\n",
      "Working for number of estimators 70 and fold 2 /5\n",
      "Working for number of estimators 70 and fold 3 /5\n",
      "Working for number of estimators 70 and fold 4 /5\n",
      "Working for number of estimators 70 and fold 5 /5\n",
      "n_estimator:  70\n",
      "cv_mean_abs_per_errors:  0.13945702462378726 \n",
      "\n",
      "Working for number of estimators 80 and fold 1 /5\n",
      "Working for number of estimators 80 and fold 2 /5\n",
      "Working for number of estimators 80 and fold 3 /5\n",
      "Working for number of estimators 80 and fold 4 /5\n",
      "Working for number of estimators 80 and fold 5 /5\n",
      "n_estimator:  80\n",
      "cv_mean_abs_per_errors:  0.13930846207971592 \n",
      "\n",
      "Working for number of estimators 90 and fold 1 /5\n",
      "Working for number of estimators 90 and fold 2 /5\n",
      "Working for number of estimators 90 and fold 3 /5\n",
      "Working for number of estimators 90 and fold 4 /5\n",
      "Working for number of estimators 90 and fold 5 /5\n",
      "n_estimator:  90\n",
      "cv_mean_abs_per_errors:  0.1392627290314799 \n",
      "\n",
      "Working for number of estimators 100 and fold 1 /5\n",
      "Working for number of estimators 100 and fold 2 /5\n",
      "Working for number of estimators 100 and fold 3 /5\n",
      "Working for number of estimators 100 and fold 4 /5\n",
      "Working for number of estimators 100 and fold 5 /5\n",
      "n_estimator:  100\n",
      "cv_mean_abs_per_errors:  0.13926305785438592 \n",
      "\n",
      "cv_mean_abs_per_errors:  [0.3633849439423973, 0.17806605709326323, 0.14427056377075045, 0.1398210999522589, 0.1395061954011377, 0.1395559301829652, 0.13945702462378726, 0.13930846207971592, 0.1392627290314799, 0.13926305785438592] \n",
      "\n",
      "optimal_n_entimator:  90\n",
      "CV_MAPE:  0.1392627290314799\n",
      "Test_MAPE:  0.12855902392024296\n",
      "CPU times: user 5min 39s, sys: 292 ms, total: 5min 39s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "def XGBRegressor_Tunning(x_train, y_train, x_test, y_test):\n",
    "    n_estimators = np.arange(10,110,10)\n",
    "    \n",
    "    #cv_mean_square_errors = []\n",
    "    cv_mean_abs_per_errors = []\n",
    "    # perform 10-fold cross validation\n",
    "    time_series_10foldcv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    for n_estimator in n_estimators:\n",
    "        clf = xgb.XGBRegressor(n_estimators = n_estimator, n_jobs = -1)\n",
    "        this_mape=[]\n",
    "        fold_number = 1\n",
    "        for train_index, cv_index in time_series_10foldcv.split(x_train):\n",
    "            print(\"Working for number of estimators\", n_estimator, \"and fold\",fold_number,\"/5\")\n",
    "            #print(\"train_index: \", train_index)\n",
    "            #print(\"cv_index: \", cv_index)\n",
    "            X_train, X_cv = x_train[train_index], x_train[cv_index]            \n",
    "            Y_train, Y_cv = y_train[train_index], y_train[cv_index]   \n",
    "            \n",
    "            clf.fit(X_train, Y_train)\n",
    "            pred = clf.predict(X_cv)\n",
    "            mae = mean_absolute_error(Y_cv, pred)\n",
    "            mape = mae/(sum(Y_cv)/len(Y_cv))\n",
    "            this_mape.append(mape)\n",
    "            fold_number = fold_number + 1\n",
    "        \n",
    "        #cv_mean_square_errors.append(np.average(this_mse))    \n",
    "        cv_mean_abs_per_errors.append(np.average(this_mape))        \n",
    "        print(\"n_estimator: \", n_estimator)\n",
    "        #print(\"cv_mean_square_error \", cv_mean_square_errors[-1])\n",
    "        print(\"cv_mean_abs_per_errors: \", cv_mean_abs_per_errors[-1],\"\\n\")\n",
    "       \n",
    "    #print(\"cv_mean_square_errors: \", cv_mean_square_errors)\n",
    "    print(\"cv_mean_abs_per_errors: \", cv_mean_abs_per_errors,\"\\n\")\n",
    "     \n",
    "    best_estimator_index_mape = cv_mean_abs_per_errors.index(min(cv_mean_abs_per_errors))\n",
    "    optimal_n_entimator = n_estimators[best_estimator_index_mape]\n",
    "    CV_MAPE = cv_mean_abs_per_errors[best_estimator_index_mape]\n",
    "    print(\"optimal_n_entimator: \", optimal_n_entimator)\n",
    "    print(\"CV_MAPE: \", CV_MAPE)    \n",
    "    \n",
    "    clf = xgb.XGBRegressor(n_estimators=optimal_n_entimator, n_jobs = -1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    mape = mae/(sum(y_test)/len(y_test))\n",
    "    print(\"Test_MAPE: \", mape)\n",
    "       \n",
    "%time XGBRegressor_Tunning(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* ### Got minimum test MAPE of 12.78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
